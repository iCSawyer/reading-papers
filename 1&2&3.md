<a name="1"></a>
## 一、Better Modeling the Programming World with Code Concept Graphs-augmented Multi-modal Learning (2018.06)

### Abstract

1. 利用多模态的形式对代码进行编码

2. 基于标识符的概念图，利用领域概念的高层关系

3. 具体而言，联合学习基于概念图的GNN，增强已存在的预训练语言模型

### Ⅰ Introduction

1. 一个软件中的数据高度异构且处于不同的层次，每个层次都可以提供结构、语义和语法信息

2. 前序工作很少考虑不同模态；<code, doc>的双模态未考虑结构化信息

### Ⅱ Code Concept Graph

1. 代码概念图：<标识符结点，类型关系>【本文提出？】

2. 联合学习、模型结合：结合模型的输出，或结合模型本身 

### Ⅴ Conclusion

1. 在同一软件构件中，可以提取不同抽象层次的数据模式

2. 可以将标识符间的语义关系抽象为概念图

3. 联合学习：侧重于代码语法的语言模型和基于代码概念图的GNN

<a name="2"></a>
## 二、Multi-Modal Attention Network Learning for Semantic Source Code Retrieval (2019.09)

### Abstract

1. 现有研究缺陷：只表示浅层特征、缺乏可解释性

2. 提出方法

   2.1 使用多模态表示：token序列、AST和CFG

   ​	a) token序列：LSTM

   ​	b) AST：Tree-LSTM（体现程序层次语法结构）

   ​	c) CFG：GGNN（体现程序计算和控制流）

   2.2 attention融合层：每个模态的不同部分赋予不同权重

   ​	不同部分指token、AST和CFG的node，以推断哪一部分对最终结果贡献更大

### Ⅰ Introduction

1. 代码检索的挑战：源代码深层语义理解、跨模态检测相似性

2. 现有工作问题：第一个应用深度网络作代码检索工作的问题有浅层次特征、缺乏可解释性等

3. 本论文解决方案和贡献

   ① 多模态表示方法，用融合层集成

   ② 首次用attention网络对同一模态的不同部分赋权，并获得可解释性

### Ⅱ Related Work

+ 包括Deep Code Representation、Multi-Modal Learning、Attention Mechanism等

+ 对于文本的attention机制：关注输入和输出的”对齐“【？】

### Ⅲ Preliminaries

1. 问题的数学表达

   + 代码片段（token、AST、CFG表示）和对应描述

   + 模型同时学习代码片段和描述的中间语义空间表示

2. 多模态学习：joint / coordinated【？】

3. 注意力机制【？】

   + 给定query、key，得到attetion value

   + 最终attention得分是对内存中值累加

### Ⅳ Multi-modal attention network

1. 概述：Online和Offline两部分

2. 多模态代码表示

   2.1 词法层面：token，LSTM

   2.2 语法层面：AST，Tree-LSTM（previous的那元只有一个forget门【？】）

   2.3 语法层面：CFG，GGNN

3. 多模态attention混合【？】

   3.1 token、AST、CFG的attention weight计算方法

   3.2 fusion：连接 + 网络处理

4. 描述表示：vallina LSTM【？】

5. 模型学习：期望预测与正确描述的高相似性

这里的图3对应的是论文1的哪个？

6. 代码检索：余弦相似度

### Ⅴ Experiments and analysis

+ 是否提高了检索性能：Yes

+ 每个modal的有效性和贡献：互补

+ 改变代码长度、AST结点数后的性能：...

+ 定性分析和可视化

还有数据集、评估标准、其他细节等。

### Ⅵ Discussion

 作用、有效性和局限性等

### Ⅶ Conclusion and future work

1. 使用了顺序特征token和结构化数据AST和CFG
2. 使用了基于attention机制的融合层
3. 模型同时学习代码表示和自然语言查询

<a name="3"></a>
## 三、Multi-Modal Learning of Editing Source Code (2021.08)

### Abstract

+ Neural Machine Translator用于编辑代码表现很好，其输入是要更改的代码，输出是补丁列表

+ 本文使用的三种模态：编辑位置、编辑代码上下文、提交信息

+ 开发者的hint可以缩小补丁搜索空间

### Ⅰ Introduction

+ 提出了一种基于三种信息模式的多模态代码编辑引擎：需要编辑的代码片段、自然语言表示的开发者意图和显式的编辑上下文
+ 以前的工作往往将上下文和编辑位置统一作为代码元素，而不是两种单独的模态

+ 使用基于transformer的已经训练过的模型PLBART来初始化参数
+ 开发者的guidance可以缩小change pattern的搜索空间
+ 用一个encoder编码所有modal，比每个modal用单独的encoder编码学习效果好

+ 论文的总结贡献

  ① 提出多模态自动代码编辑工具MODIT，通过context和guidence

  ② 关于modal的作用、encoder/decoder的变化给了一些经验教训

### Ⅱ Background

1. 神经机器翻译：encoder-decoder，将句子从一种语言翻译到另一种语言

2. 用Transformer进行序列处理

   2.1 不同于传统RNN模型token顺序处理，Transformer假定序列中的每一对token有soft-dependency【？】

   2.2 dependency权重通过attention机制进行学习

3. 源代码的迁移学习

   3.1 迁移学习：学习源代码不可知表示并重用

   3.2 目标：通过大量源代码预先训练，期望理解或生成代码

### Ⅲ MODIT

（尽管edit location属于context，但仍然作为不同模式处理）

1. 预处理

   token-subtoken【？】

2. Encoder-Decoder模型【？】

   2.1 编码器：多模态统一编码和表示

   2.2 解码器：self-attention和cross-attention【？】

3. 输出生成

### Ⅳ Experiment Design

数据集、数据准备（模式如何提取的...）、训练、评价标准（top-1 accuracy）

### Ⅴ Empirical Results

1. MODIT准确度如何

   1.1 guidance缩小pattern搜索空间，context缩小token搜索空间

   1.2 Transformer无需监督也可学习；用预训练模型初始化参数效果明显更好

2. 不同模态的作用

   2.1 每个模态都有用，缺失任何一个都会导致性能下降（尽管待编辑代码属于上下文的一个部分）

   2.2 显式的上下文可以让模型选择合适的标识符

   2.3 隔离有缺陷的代码后性能更好

3. encoder和decoder不同带来的改变

   3.1 单一encoder学习所有modal效果更好

   3.2 通过基于attention的跨模态推理，代码表示更鲁棒

### Ⅵ Discussion

1. 编辑位置

   + 假设：不知道编辑位置，将整个函数输入，期待MODIT输出整个函数

   + 结果：有开发者的guidance仍然可以提高性能

2. 源代码的tokenization：本文用subword（其他各种分词法【？】）

### Ⅸ Conclusion

1. 多模态很有用：location、context、guidance

2. 给了一些关于模态、encoder/decoder改变等带来的影响

## 四、阅读想法

1. 总结（或提出）各种可能能够利用的模态

   上文提到过的有：

   ​	非结构化：代码token序列、编辑位置、上下文、开发者注释

   ​	结构化：代码概念图、语法树、控制流图

2. 如何对几种模态进行处理也会对性能产生影响

   如：

   ​	encoder/decoder的工作方式

   ​	模型本身结合，或对模型输出进行结合

3. 后两篇论文都提到了Attention机制和Transformer，值得关注；我们的工作与NLP和CV的工作可能存在某些联系，如代码检索 - 图像检索等

4. 阅读感受

   对论文的阅读主要关注在它的idea层面；

   关于具体的模型设计、训练和对应的实验设计、结果等，由于缺乏NLP、深度学习相关知识和对应的实践，理解还比较困难

>  【？】*表示不太理解的地方*

